{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Copyright **`(c)`** 2022 Giovanni Squillero `<squillero@polito.it>`  \n",
    "[`https://github.com/squillero/computational-intelligence`](https://github.com/squillero/computational-intelligence)  \n",
    "Free for personal or classroom use; see [`LICENSE.md`](https://github.com/squillero/computational-intelligence/blob/master/LICENSE.md) for details.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# Lab 2: ES\n",
    "\n",
    "## Task\n",
    "\n",
    "Write agents able to play [*Nim*](https://en.wikipedia.org/wiki/Nim), with an arbitrary number of rows and an upper bound $k$ on the number of objects that can be removed in a turn (a.k.a., *subtraction game*).\n",
    "\n",
    "The goal of the game is to **avoid** taking the last object.\n",
    "\n",
    "* Task2.1: An agent using fixed rules based on *nim-sum* (i.e., an *expert system*)\n",
    "* Task2.2: An agent using evolved rules using ES\n",
    "\n",
    "## Instructions\n",
    "\n",
    "* Create the directory `lab2` inside the course repo \n",
    "* Put a `README.md` and your solution (all the files, code and auxiliary data if needed)\n",
    "\n",
    "## Notes\n",
    "\n",
    "* Working in group is not only allowed, but recommended (see: [Ubuntu](https://en.wikipedia.org/wiki/Ubuntu_philosophy) and [Cooperative Learning](https://files.eric.ed.gov/fulltext/EJ1096789.pdf)). Collaborations must be explicitly declared in the `README.md`.\n",
    "* [Yanking](https://www.emacswiki.org/emacs/KillingAndYanking) from the internet is allowed, but sources must be explicitly declared in the `README.md`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from pprint import pprint, pformat\n",
    "from collections import namedtuple\n",
    "import random\n",
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_ROWS = 5\n",
    "N_AGENTS_IN_ENVIRONMENT = 100\n",
    "N_REPETITION = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The *Nim* and *Nimply* classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nimply = namedtuple(\"Nimply\", \"row, num_objects\")\n",
    "\n",
    "class Nim:\n",
    "    def __init__(self, num_rows: int, k: int = None) -> None:\n",
    "        self._rows = [i * 2 + 1 for i in range(num_rows)]\n",
    "        self._k = k\n",
    "\n",
    "    def __bool__(self):\n",
    "        return sum(self._rows) > 0\n",
    "\n",
    "    def __str__(self):\n",
    "        return \"<\" + \" \".join(str(_) for _ in self._rows) + \">\"\n",
    "\n",
    "    @property\n",
    "    def rows(self) -> tuple:\n",
    "        return tuple(self._rows)\n",
    "\n",
    "    def nimming(self, ply: Nimply) -> None:\n",
    "        row, num_objects = ply\n",
    "        assert self._rows[row] >= num_objects\n",
    "        assert self._k is None or num_objects <= self._k\n",
    "        self._rows[row] -= num_objects\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample (and silly) startegies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pure_random(state: Nim) -> Nimply:\n",
    "    \"\"\"A completely random move\"\"\"\n",
    "    row = random.choice([r for r, c in enumerate(state.rows) if c > 0])\n",
    "    num_objects = random.randint(1, state.rows[row])\n",
    "    return Nimply(row, num_objects)\n",
    "\n",
    "def gabriele(state: Nim) -> Nimply:\n",
    "    \"\"\"Pick always the maximum possible number of the lowest row\"\"\"\n",
    "    possible_moves = [(r, o) for r, c in enumerate(state.rows) for o in range(1, c + 1)]\n",
    "    return Nimply(*max(possible_moves, key=lambda m: (-m[0], m[1])))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimal strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def nim_sum(state: Nim) -> int:\n",
    "    tmp = np.array([tuple(int(x) for x in f\"{c:032b}\") for c in state.rows])\n",
    "    xor = tmp.sum(axis=0) % 2\n",
    "    return int(\"\".join(str(_) for _ in xor), base=2)\n",
    "\n",
    "\n",
    "def analize(raw: Nim) -> dict:\n",
    "    cooked = dict()\n",
    "    cooked[\"possible_moves\"] = dict()\n",
    "    for ply in (Nimply(r, o) for r, c in enumerate(raw.rows) for o in range(1, c + 1)):\n",
    "        tmp = deepcopy(raw)\n",
    "        tmp.nimming(ply)\n",
    "        cooked[\"possible_moves\"][ply] = nim_sum(tmp)\n",
    "    return cooked\n",
    "\n",
    "\n",
    "def optimal(state: Nim) -> Nimply:\n",
    "    analysis = analize(state)\n",
    "    logging.debug(f\"analysis:\\n{pformat(analysis)}\")\n",
    "\n",
    "    number_of_heaps_that_has_two_or_more_objects = sum(np.array(state.rows) >= 2)\n",
    "    number_of_heaps_that_has_objects = sum(np.array(state.rows) > 0)\n",
    "\n",
    "    if number_of_heaps_that_has_two_or_more_objects > 1:\n",
    "        spicy_moves = [ply for ply, ns in analysis[\"possible_moves\"].items() if ns == 0]\n",
    "        if not spicy_moves:\n",
    "            spicy_moves = list(analysis[\"possible_moves\"].keys())\n",
    "        ply = random.choice(spicy_moves)\n",
    "    elif number_of_heaps_that_has_two_or_more_objects == 1:\n",
    "        if number_of_heaps_that_has_objects % 2 == 0:\n",
    "            heaps = np.array(state.rows)\n",
    "            index = np.argwhere(heaps >= 2).flatten()[0]\n",
    "            number_of_objects_to_remove = heaps[index]\n",
    "\n",
    "            ply = Nimply(int(index), int(number_of_objects_to_remove))\n",
    "        else:\n",
    "            heaps = np.array(state.rows)\n",
    "            index = np.argwhere(heaps >= 2).flatten()[0]\n",
    "            number_of_objects_to_remove = heaps[index]\n",
    "\n",
    "            ply = Nimply(int(index), int(number_of_objects_to_remove - 1))\n",
    "    else:\n",
    "        spicy_moves = [ply for ply, ns in analysis[\"possible_moves\"].items() if ns == 0]\n",
    "        if not spicy_moves:\n",
    "            spicy_moves = list(analysis[\"possible_moves\"].keys())\n",
    "        ply = random.choice(spicy_moves)\n",
    "        \n",
    "    return ply\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adaptive Agent and Customized Agent based on predefined strategy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdaptiveAgent():\n",
    "    def __init__(self, num_rows, W = None):\n",
    "        self.num_rows = num_rows\n",
    "        if W is None:\n",
    "            self.W = np.random.random(size = (4 * num_rows,num_rows))\n",
    "        else:\n",
    "            self.W = W\n",
    "\n",
    "    def get_action(self, state:Nim) -> Nimply:\n",
    "        input = np.array(state.rows)\n",
    "        result = np.dot(self.W, input)\n",
    "\n",
    "        return self.interpret(result, state)\n",
    "\n",
    "    def interpret(self, output, state:Nim):\n",
    "        rows = state.rows\n",
    "        actions = np.flip(np.argsort(output))\n",
    "\n",
    "        for chosen_action in actions:\n",
    "            index = int(chosen_action // 4)\n",
    "            action = chosen_action % 4\n",
    "\n",
    "            # 0 is take 1\n",
    "            # 1 is take 2\n",
    "            # 2 is take all but one\n",
    "            # 3 is take all\n",
    "            if action == 0:\n",
    "                if rows[index] >= 1:\n",
    "                    return Nimply(index, 1)\n",
    "                else:\n",
    "                    continue\n",
    "            elif action == 1:\n",
    "                if rows[index] >= 2:\n",
    "                    return Nimply(index, 2)\n",
    "                else:\n",
    "                    continue\n",
    "            elif action == 2:\n",
    "                if rows[index] > 1:\n",
    "                    return Nimply(index, int(rows[index]) - 1)\n",
    "                else:\n",
    "                    continue\n",
    "            else:\n",
    "                if rows[index] > 0:\n",
    "                    return Nimply(index, int(rows[index]))\n",
    "                else: \n",
    "                    continue\n",
    "        \n",
    "class CustomAgent():\n",
    "\n",
    "    def __init__(self, intelligence):\n",
    "        self.intelligence = intelligence\n",
    "    \n",
    "    def get_action(self, state: Nim):\n",
    "        if random.random() < self.intelligence:\n",
    "            return optimal(state)\n",
    "        else:\n",
    "            return pure_random(state)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Oversimplified match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:init : <1 3 5 7 9>\n",
      "INFO:root:ply: player 0 plays Nimply(row=4, num_objects=9)\n",
      "INFO:root:status: <1 3 5 7 0>\n",
      "INFO:root:ply: player 1 plays Nimply(row=0, num_objects=1)\n",
      "INFO:root:status: <0 3 5 7 0>\n",
      "INFO:root:ply: player 0 plays Nimply(row=1, num_objects=1)\n",
      "INFO:root:status: <0 2 5 7 0>\n",
      "INFO:root:ply: player 1 plays Nimply(row=1, num_objects=2)\n",
      "INFO:root:status: <0 0 5 7 0>\n",
      "INFO:root:ply: player 0 plays Nimply(row=3, num_objects=2)\n",
      "INFO:root:status: <0 0 5 5 0>\n",
      "INFO:root:ply: player 1 plays Nimply(row=3, num_objects=3)\n",
      "INFO:root:status: <0 0 5 2 0>\n",
      "INFO:root:ply: player 0 plays Nimply(row=2, num_objects=3)\n",
      "INFO:root:status: <0 0 2 2 0>\n",
      "INFO:root:ply: player 1 plays Nimply(row=3, num_objects=2)\n",
      "INFO:root:status: <0 0 2 0 0>\n",
      "INFO:root:ply: player 0 plays Nimply(row=2, num_objects=1)\n",
      "INFO:root:status: <0 0 1 0 0>\n",
      "INFO:root:ply: player 1 plays Nimply(row=2, num_objects=1)\n",
      "INFO:root:status: <0 0 0 0 0>\n",
      "INFO:root:status: Player 0 won!\n"
     ]
    }
   ],
   "source": [
    "logging.getLogger().setLevel(logging.INFO)\n",
    "\n",
    "strategy = (optimal, pure_random)\n",
    "\n",
    "nim = Nim(5)\n",
    "logging.info(f\"init : {nim}\")\n",
    "player = 0\n",
    "while nim:\n",
    "    ply = strategy[player](nim)\n",
    "    logging.info(f\"ply: player {player} plays {ply}\")\n",
    "    nim.nimming(ply)\n",
    "    logging.info(f\"status: {nim}\")\n",
    "    player = 1 - player\n",
    "logging.info(f\"status: Player {player} won!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitness function & Environment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool = []\n",
    "\n",
    "for n in range(N_AGENTS_IN_ENVIRONMENT):\n",
    "    pool.append(CustomAgent(n / N_AGENTS_IN_ENVIRONMENT))\n",
    "\n",
    "def fitness(adaptive_agent):\n",
    "    count = 0 \n",
    "\n",
    "    for epoch in range(N_REPETITION):\n",
    "        for competing_agent in pool:\n",
    "            adaptive = lambda x : adaptive_agent.get_action(x)\n",
    "            compete = lambda x :  competing_agent.get_action(x)\n",
    "\n",
    "            strategy = (adaptive, compete)\n",
    "\n",
    "            nim = Nim(N_ROWS)\n",
    "            #logging.info(f\"init : {nim}\")\n",
    "            player = 0\n",
    "            while nim:\n",
    "                ply = strategy[player](nim)\n",
    "                #logging.info(f\"ply: player {player} plays {ply}\")\n",
    "                nim.nimming(ply)\n",
    "                #logging.info(f\"status: {nim}\")\n",
    "                player = 1 - player\n",
    "            #logging.info(f\"status: Player {player} won!\")\n",
    "\n",
    "            if player == 0:\n",
    "                count += 1\n",
    "    \n",
    "    return count / N_REPETITION \n",
    "\n",
    "def eval(offsprings):\n",
    "    result = []\n",
    "\n",
    "    for W in offsprings:\n",
    "        adaptive_agent = AdaptiveAgent(num_rows = N_ROWS, W = W)\n",
    "        result.append(fitness(adaptive_agent))\n",
    "    \n",
    "    if len(result) == 1:\n",
    "        return result[0]\n",
    "    else:\n",
    "        return result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 + Lambda Strategy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef980834feec41fa8ccbf45fdd825f3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ld = 20 \n",
    "sigma = 0.1\n",
    "\n",
    "solution = np.random.random(size = (4*5, 5))\n",
    "history = []\n",
    "best = np.copy(solution)\n",
    "best_value = eval([best])\n",
    "\n",
    "for n in tqdm(range(1000 // ld)):\n",
    "    offsprings = (\n",
    "        np.random.normal(loc = 0, scale = sigma, size = (ld, 4*N_ROWS, N_ROWS)) + solution\n",
    "    )\n",
    "\n",
    "    evals = eval(offsprings)\n",
    "    solution = offsprings[np.argmax(evals)]\n",
    "    solution_value = evals[np.argmax(evals)]\n",
    "    \n",
    "    if best_value < solution_value:\n",
    "        best_value = solution_value\n",
    "        best = np.copy(solution)\n",
    "        history.append((n, solution_value))\n",
    "\n",
    "#logging.info(f\"Best solution: {rastrigin(best_so_far)}\")\n",
    "\n",
    "#history = np.array(history)\n",
    "#plt.figure(figsize=(14, 4))\n",
    "#plt.plot(history[:, 0], history[:, 1], marker=\".\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 36.2), (1, 42.4)]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 ('ci22-dPIXJ0_o-py3.10')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "10197e8e2f2aa67e2c349105091c77f4cd384fce4877865f002d9ec653f96bc0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
