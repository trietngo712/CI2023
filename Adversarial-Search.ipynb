{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adversarial Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Goal: *optimal policy*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Taxonomy\n",
    "- Deterministic vs Probabilistic\n",
    "- Perfect information vs Imperfect information\n",
    "- Turn-based vs Real-time\n",
    "- Zero sum vs Non-zero sum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We don't know how the opponent will behave. The solution is not a fixed sequence of actions from start state to goal stat, but a strategy or policy (a mapping from state to best move in that state)\n",
    "- Efficiency is critical to playing well\n",
    "    - The time to make a move is limited\n",
    "    - The branching factor, search depth, and number of terminal configurations are huge\n",
    "    - This rules out serching all the way to the end of the game"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deterministic Games\n",
    "\n",
    "- Players\n",
    "- States\n",
    "    - Termnial test\n",
    "    - Termnial utility (static evaluation)\n",
    "- Actions\n",
    "     - Transition function\n",
    "\n",
    "### Game Tree\n",
    " - Branching factor\n",
    " - Depth\n",
    " - Symmetries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MinMax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- A decision rule used for minimizing the possible loss for a worst case (maximum loss) scenario which is different from trying to maximizing the chance of winning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Complete only if tree is finite\n",
    "- Optimal against an optimal opponent\n",
    "- Complexity\n",
    "    - Time: O(b^m)\n",
    "    - Space: O(bm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2+ players game"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Utilities are tuples\n",
    "- Each player maximized their own utility at their node\n",
    "- State space is really huge\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ALpha beta Pruning\n",
    "- Compute upper \\alpha and lower \\beta bounds on final minimax values as we go to identify such cases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Chess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limit Depth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Hard cut off: limit the depth of the search at a certain level\n",
    "- Horizon effect:\n",
    "    - Incorrectly estimate the state...\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cut off problems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Quiescence search:\n",
    "    - Increase depth when evaluating volatile positions\n",
    "    - How can volatile and quiet positions be discriminated\n",
    "- Singular extension:\n",
    "    - Add selectivity to brute force searching by increasing depth on selected singular moves\n",
    "    - Singular moves are moves that return a value much better than all their alternatives and are likely to affect the outcome of the search if their value change (5-20% in chess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Other techniques:\n",
    "    - Hash table to store previously expanded states\n",
    "    - Forward prining to avoid considering all possible moves\n",
    "        - Rankcut: how likely is that a remaining move is better than the current best move\n",
    "    - Lookup tables for opening moves and endgames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Heuristic evaluation:\n",
    "    - Deep Blue evaluation 8k features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stochastic game"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Stochasticity: how can we incorporate dice throwing into the game tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- minimax:\n",
    "    - maximize over all possible moves i can make\n",
    "    - minimize over all possible moves the opponent can make of the reward\n",
    "\n",
    "- value(node) = max_mymoves (min_opponentmoves (Reward))\n",
    "\n",
    "- in stochastic minimax\n",
    "\n",
    "- value(node) = max_mymoves (min_opponentmoves(E(reward)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
